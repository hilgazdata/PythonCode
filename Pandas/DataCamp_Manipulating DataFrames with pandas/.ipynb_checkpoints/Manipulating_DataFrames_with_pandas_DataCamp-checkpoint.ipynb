{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extracting and transforming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional and labeled indexing "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Assign the row position of election.loc['Bedford']: x\n",
    "x = 4\n",
    "\n",
    "# Assign the column position of election['winner']: y\n",
    "y = 4\n",
    "\n",
    "# Print the boolean equivalence\n",
    "print(election.iloc[x, y] == election.loc['Bedford', 'winner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and column arrangement"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read in filename and set the index: election\n",
    "election = pd.read_csv(filename, index_col='county')\n",
    "\n",
    "%%%%%%%%%%%% CREATE A SEPARATE DATAFRAME WITH THE COLUMNS %%%%%%%%%%%%%%%%\n",
    "\n",
    "# Create a separate dataframe with the columns ['winner', 'total', 'voters']: results   \n",
    "\n",
    "results = election[['winner', 'total', 'voters']]\n",
    "\n",
    "# Print the output of results.head()\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing rows"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Slice the row labels 'Perry' to 'Potter': p_counties\n",
    "p_counties = election.loc['Perry':'Potter']\n",
    "\n",
    "# Print the p_counties DataFrame\n",
    "print(p_counties)\n",
    "\n",
    "# Slice the row labels 'Potter' to 'Perry' in reverse order. To do this for hypothetical row labels 'a' and 'b', you could use a stepsize of -1 like so: df.loc['b':'a':-1].\n",
    "\n",
    "p_counties_rev = election.loc['Potter':'Perry':-1]\n",
    "\n",
    "# Print the p_counties_rev DataFrame\n",
    "print(p_counties_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## slicing columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Slice the columns from the starting column to 'Obama': left_columns\n",
    "left_columns = election.loc[:,:'Obama']\n",
    "\n",
    "# Print the output of left_columns.head()\n",
    "print(left_columns.head())\n",
    "\n",
    "# Slice the columns from 'Obama' to 'winner': middle_columns\n",
    "middle_columns = election.loc[:,'Obama':'winner']\n",
    "\n",
    "# Print the output of middle_columns.head()\n",
    "print(middle_columns.head())\n",
    "\n",
    "# Slice the columns from 'Romney' to the end: 'right_columns'\n",
    "right_columns = election.loc[:,'Romney':]\n",
    "\n",
    "# Print the output of right_columns.head()\n",
    "print(right_columns.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subselecting DataFrames with lists"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create the list of row labels: rows\n",
    "rows = ['Philadelphia', 'Centre', 'Fulton']\n",
    "\n",
    "# Create the list of column labels: cols\n",
    "cols = ['winner', 'Obama', 'Romney']\n",
    "\n",
    "%%%%%%%%%%%%%%%%%%%%%%CREATE THE NEW DATAFRAME USING ROW AND COLUMN LISTS%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Create the new DataFrame: three_counties\n",
    "three_counties = election.loc[rows,cols]\n",
    "\n",
    "# Print the three_counties DataFrame\n",
    "print(three_counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create the boolean array: high_turnout\n",
    "high_turnout = election.turnout > 70\n",
    "\n",
    "# or\n",
    "\n",
    "high_turnout = election['turnout'] > 70\n",
    "\n",
    "# Filter the election DataFrame with the high_turnout array: high_turnout_df\n",
    "high_turnout_df = election.loc[high_turnout]\n",
    "\n",
    "# Print the high_turnout_results DataFrame\n",
    "print(high_turnout_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtering columns using other columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Create a boolean array for the condition where the 'margin' column is less than 1 and assign it to too_close.\n",
    "\n",
    "too_close = election['margin'] < 1\n",
    "\n",
    "# Assign np.nan to the 'winner' column where the results were too close to call\n",
    "election.loc[too_close, 'winner'] = np.nan\n",
    "\n",
    "# Print the output of election.info()\n",
    "print(election.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering using NaNs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Select the 'age' and 'cabin' columns: df\n",
    "df = titanic[['age','cabin']]\n",
    "\n",
    "# Print the shape of df\n",
    "print(df.shape)\n",
    "\n",
    "# Drop rows in df with how='any' and print the shape\n",
    "print(df.dropna(how='any').shape)\n",
    "\n",
    "# Drop rows in df with how='all' and print the shape\n",
    "print(df.dropna(how='all').shape)\n",
    "\n",
    "# Drop columns in titanic with less than 1000 non-missing values\n",
    "print(titanic.dropna(thresh=1000, axis='columns').info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using apply() to transform a column"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write a function to convert degrees Fahrenheit to degrees Celsius: to_celsius\n",
    "def to_celsius(F):\n",
    "    return 5/9*(F - 32)\n",
    "\n",
    "# Apply the to_celsius() function over the ['Mean TemperatureF','Mean Dew PointF'] columns of the weather DataFrame.\n",
    "\n",
    "df_celsius = weather[['Mean TemperatureF','Mean Dew PointF']].apply(to_celsius)\n",
    "\n",
    "# Reassign the column labels of df_celsius to ['Mean TemperatureC','Mean Dew PointC'] using the .columns attribute.\n",
    "\n",
    "df_celsius.columns = ['Mean TemperatureC', 'Mean Dew PointC']\n",
    "\n",
    "# Print the output of df_celsius.head()\n",
    "print(df_celsius.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using map() with a dictionary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a dictionary with the key:value pairs 'Obama':'blue' and 'Romney':'red'\n",
    "red_vs_blue = {'Obama':'blue','Romney':'red'}\n",
    "\n",
    "# Use the .map() method on the 'winner' column using the red_vs_blue dictionary you created.\n",
    "election['color'] = election.winner.map(red_vs_blue)\n",
    "\n",
    "# Print the output of election.head()\n",
    "print(election.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using vectorized functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import zscore from scipy.stats\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Call zscore with election['turnout'] as input: turnout_zscore\n",
    "\n",
    "turnout_zscore = zscore(election['turnout'])\n",
    "\n",
    "# Print the type of turnout_zscore\n",
    "print(type(turnout_zscore))\n",
    "\n",
    "# Assign turnout_zscore to a new column: election['turnout_zscore']\n",
    "election['turnout_zscore'] = turnout_zscore\n",
    "\n",
    "# Print the output of election.head()\n",
    "print(election.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Advanced Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing index of a DataFrame"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a list new_idx with the same elements as in sales.index, but with all characters capitalized.\n",
    "new_idx = [month.upper() for month in sales.index]\n",
    "\n",
    "# Assign new_idx to sales.index\n",
    "sales.index = new_idx\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing index name labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Assign the string 'MONTHS' to sales.index.name\n",
    "sales.index.name = 'MONTH'\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(sales)\n",
    "\n",
    "# Assign the string 'PRODUCTS' to sales.columns.name \n",
    "sales.columns.name  = 'PRODUCTS'\n",
    "\n",
    "# Print the sales dataframe again\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an index, then a DataFrame\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Generate the list of months: months\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']\n",
    "\n",
    "# Assign months to sales.index\n",
    "sales.index = months\n",
    "\n",
    "# Print the modified sales DataFrame\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiIndex -- Hierarchical Indexing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data with a MultiIndex"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print sales.loc[['CA', 'TX']]\n",
    "print(sales.loc[['CA', 'TX']])\n",
    "\n",
    "# Print sales['CA':'TX']\n",
    "print(sales['CA':'TX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting & sorting a MultiIndex\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Set the index to be the columns ['state', 'month']: sales\n",
    "sales = sales.set_index(['state', 'month'])\n",
    "\n",
    "# Sort the MultiIndex: sales\n",
    "sales = sales.sort_index()\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using .loc[] with nonunique indexes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Set the index to the column 'state': sales\n",
    "sales = sales.set_index('state')\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(sales)\n",
    "\n",
    "# Access the data from 'NY'\n",
    "print(sales.loc['NY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing multiple levels of a MultiIndex\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Look up data for NY in month 1 in sales: NY_month1\n",
    "NY_month1 = sales.loc[('NY',1), :]\n",
    "\n",
    "# Look up data for CA and TX in month 2: CA_TX_month2\n",
    "CA_TX_month2 = sales.loc[(['CA','TX'],2), :]\n",
    "\n",
    "# Access the inner month index and look up data for all states in month 2: all_month2\n",
    "all_month2 = sales.loc[(slice(None), 2), :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Rearranging and Reshaping Data (Pivoting DataFrames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting a single variable"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Pivot the users DataFrame with the rows indexed by 'weekday', the columns indexed by 'city', and the values populated with 'visitors'.\n",
    "\n",
    "visitors_pivot = users.pivot(index = 'weekday', columns = 'city', values = 'visitors')\n",
    "\n",
    "# Print the pivoted DataFrame\n",
    "print(visitors_pivot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting all variables\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Pivot the users DataFrame with the 'signups' indexed by 'weekday' in the rows and 'city' in the columns.\n",
    "\n",
    "signups_pivot = users.pivot(index='weekday', columns='city', values='signups')\n",
    "\n",
    "# Print signups_pivot\n",
    "print(signups_pivot)\n",
    "\n",
    "# Pivot the users DataFrame with both 'signups' and 'visitors' pivoted - that is, all the variables. This will happen automatically if you do not specify an argument for the values parameter of .pivot().\n",
    "\n",
    "pivot = signups_pivot = users.pivot(index = 'weekday', columns = 'city')\n",
    "\n",
    "# Print the pivoted DataFrame\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking and unstacking \n",
    "\n",
    "### This is the same as pivoting, but with multiIndexed DataFrames"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Unstack users by 'weekday': byweekday\n",
    "byweekday = users.unstack(level='weekday')\n",
    "\n",
    "# Print the byweekday DataFrame\n",
    "print(byweekday)\n",
    "\n",
    "# Stack byweekday by 'weekday' and print it\n",
    "print(byweekday.stack(level='weekday'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restoring the index order"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The goal here is to convert bycity back to something that looks like users.\n",
    "\n",
    "# Define a DataFrame newusers with the 'city' level stacked back into the index of bycity.\n",
    "newusers = bycity.stack(level='city')\n",
    "\n",
    "# Swap the levels of the index of newusers: newusers\n",
    "newusers = newusers.swaplevel(0,1)\n",
    "\n",
    "# Print newusers and verify that the index is not sorted\n",
    "print(newusers)\n",
    "\n",
    "# Sort the index of newusers: newusers\n",
    "newusers = newusers.sort_index()\n",
    "\n",
    "# Print newusers and verify that the index is now sorted\n",
    "print(newusers)\n",
    "\n",
    "# Verify that the new DataFrame is equal to the original\n",
    "print(newusers.equals(users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melting data\n",
    "\n",
    "###  the goal of melting is to restore a pivoted DataFrame to its original form, or to change it from a wide shape to a long shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding names for readability"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Reset the index: visitors_by_city_weekday\n",
    "visitors_by_city_weekday = visitors_by_city_weekday.reset_index() \n",
    "\n",
    "# Print visitors_by_city_weekday\n",
    "print(visitors_by_city_weekday)\n",
    "\n",
    "# Melt visitors_by_city_weekday to move the city names from the column labels to values in a single column called visitors.\n",
    "\n",
    "visitors = pd.melt(visitors_by_city_weekday, id_vars='weekday', value_name='visitors')\n",
    "\n",
    "# Print visitors\n",
    "print(visitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going from wide to long\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define a DataFrame skinny where you melt the 'visitors' and 'signups' columns of users into a single column. Note that we don't define these specified two in the command\n",
    "\n",
    "skinny = pd.melt(users, value_vars=['visitors', 'signups'], id_vars=['weekday','city'])\n",
    "\n",
    "# Print skinny\n",
    "print(skinny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### or when you dont specify the var_name or value_name parameters, the melted DataFrame has the default variable and value column names.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define a DataFrame skinny where you melt the 'visitors' and 'signups' columns of users into a single column. Note that we don't define these specified two in the command\n",
    "\n",
    "skinny = pd.melt(users, id_vars=['weekday','city'])\n",
    "\n",
    "# Print skinny\n",
    "print(skinny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining key-value pairs with melt()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Set the new index: users_idx\n",
    "users_idx = users.set_index(['city','weekday'])\n",
    "\n",
    "# Print the users_idx DataFrame\n",
    "print(users_idx)\n",
    "\n",
    "# Obtain the key-value pairs corresponding to visitors and signups by melting users_idx with the keyword argument col_level=0.\n",
    "\n",
    "kv_pairs = pd.melt(users_idx, col_level=0)\n",
    "\n",
    "# Print the key-value pairs\n",
    "print(kv_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot tables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use pivot tables, especially when there are rows with the same values of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a pivot table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Use a pivot table to index the rows of users by 'weekday' and the columns of users by 'city'. These correspond to the index and columns parameters of .pivot_table().\n",
    "\n",
    "by_city_day = users.pivot_table(index='weekday',columns='city')\n",
    "\n",
    "# Print by_city_day\n",
    "print(by_city_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using other aggregations in pivot tables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define a DataFrame count_by_weekday1 that shows the count of each column with the parameter aggfunc='count. The index here is 'weekday'.\n",
    "\n",
    "count_by_weekday1 = users.pivot_table(index='weekday',aggfunc='count')\n",
    "\n",
    "# Print count_by_weekday\n",
    "print(count_by_weekday1)\n",
    "\n",
    "# Replace aggfunc='count' with aggfunc=len and verify you obtain the same result.\n",
    "count_by_weekday2 = users.pivot_table(index='weekday',aggfunc=len)\n",
    "\n",
    "# Verify that the same result is obtained\n",
    "print('==========================================')\n",
    "print(count_by_weekday1.equals(count_by_weekday2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using margins in pivot tables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define a DataFrame signups_and_visitors that shows the breakdown of signups and visitors by day.\n",
    "## You will need to use aggfunc=sum to do this.\n",
    "\n",
    "signups_and_visitors = users.pivot_table(index='weekday', aggfunc=sum)\n",
    "\n",
    "# Print signups_and_visitors\n",
    "print(signups_and_visitors)\n",
    "\n",
    "# Add in the margins: signups_and_visitors_total \n",
    "signups_and_visitors_total = users.pivot_table(index='weekday', aggfunc=sum, margins=True)\n",
    "\n",
    "# Print signups_and_visitors_total\n",
    "print(signups_and_visitors_total)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "         signups  visitors\n",
    "weekday                   \n",
    "Mon            8       782\n",
    "Sun           19       376\n",
    "\n",
    "\n",
    "         signups  visitors\n",
    "weekday                   \n",
    "Mon            8       782\n",
    "Sun           19       376\n",
    "All           27      1158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Grouping Data (categoricals and groupby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by multiple columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Your job is to first group by the 'pclass' column and count the number of rows in each class using the 'survived' column. You will then group by the 'embarked' and 'pclass' columns and count the number of passengers.\n",
    "\n",
    "# Group by the 'pclass' column and save the result as by_class.\n",
    "by_class = titanic.groupby('pclass')\n",
    "\n",
    "# Aggregate the 'survived' column of by_class using .count(). Save the result as count_by_class.\n",
    "count_by_class = by_class.survived.count()\n",
    "\n",
    "# Print count_by_class\n",
    "print(count_by_class)\n",
    "\n",
    "# Group titanic by the 'embarked' and 'pclass' columns. Save the result as by_mult.\n",
    "by_mult = titanic.groupby(['embarked','pclass'])\n",
    "\n",
    "# Aggregate the 'survived' column of by_mult using .count(). Save the result as count_mult.\n",
    "count_mult = by_mult['survived'].count()\n",
    "\n",
    "# Print count_mult\n",
    "print(count_mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by another series\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Read life_fname into a DataFrame: life\n",
    "life = pd.read_csv(life_fname, index_col='Country')\n",
    "\n",
    "# Read regions_fname into a DataFrame called regions and set the index to 'Country'.\n",
    "\n",
    "regions = pd.read_csv(regions_fname, index_col='Country')\n",
    "\n",
    "# Group life by regions['region']: life_by_region\n",
    "life_by_region = life.groupby(regions.region)\n",
    "\n",
    "# Print the mean over the '2010' column of life_by_region\n",
    "print((life_by_region['2010']).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing multiple aggregates of multiple columns\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Group titanic by 'pclass': by_class\n",
    "by_class = titanic.groupby('pclass')\n",
    "\n",
    "# Select 'age' and 'fare'\n",
    "by_class_sub = by_class[['age','fare']]\n",
    "\n",
    "# Aggregate by_class_sub by 'max' and 'median': aggregated\n",
    "aggregated = by_class_sub.agg(['max','median'])\n",
    "\n",
    "# Print the maximum age in each class\n",
    "print(aggregated.loc[:, ('age','max')])\n",
    "\n",
    "# Print the median fare in each class\n",
    "print(aggregated.loc[:, ('fare','median')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating on index levels/fields\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Read the CSV file into a DataFrame and sort the index: gapminder\n",
    "gapminder = pd.read_csv('gapminder.csv', index_col=['Year','region','Country']).sort_index()\n",
    "\n",
    "# Group gapminder by 'Year' and 'region': by_year_region\n",
    "by_year_region = gapminder.groupby(level=['Year','region'])\n",
    "\n",
    "# Define the function to compute spread: spread\n",
    "def spread(series):\n",
    "    return series.max() - series.min()\n",
    "\n",
    "# Create the dictionary: aggregator\n",
    "aggregator = {'population':'sum', 'child_mortality':'mean', 'gdp':spread}\n",
    "\n",
    "# Aggregate by_year_region using the dictionary: aggregated\n",
    "aggregated = by_year_region.agg(aggregator)\n",
    "\n",
    "# Print the last 6 entries of aggregated \n",
    "print(aggregated.tail(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping on a function of the index\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Read file: sales\n",
    "sales = pd.read_csv('sales.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Create a groupby object with sales.index.strftime('%a') as input and assign it to by_day.\n",
    "by_day = sales.groupby(sales.index.strftime('%a'))\n",
    "\n",
    "# Aggregate the 'Units' column of by_day with the .sum() method. Save the result as units_sum.\n",
    "units_sum = by_day['Units'].sum()\n",
    "\n",
    "# Print units_sum\n",
    "print(units_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling missing data (imputation) by group\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a groupby object: by_sex_class\n",
    "by_sex_class = titanic.groupby(['sex','pclass'])\n",
    "\n",
    "# Write a function that imputes median\n",
    "def impute_median(series):\n",
    "    return series.fillna(series.median())\n",
    "\n",
    "# Impute age and assign to titanic.age\n",
    "titanic.age = by_sex_class.age.transform(impute_median)\n",
    "\n",
    "# Print the output of titanic.tail(10)\n",
    "print(titanic.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other transformations with .apply\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Group gapminder_2010 by 'region': regional\n",
    "regional = gapminder_2010.groupby('region')\n",
    "\n",
    "# Apply the disparity function on regional: reg_disp\n",
    "reg_disp = regional.apply(disparity)\n",
    "\n",
    "# Print the disparity of 'United States', 'United Kingdom', and 'China'\n",
    "print(reg_disp.loc[['United States','United Kingdom','China']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and filtering with .apply()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a groupby object using titanic over the 'sex' column: by_sex\n",
    "by_sex = titanic.groupby('sex')\n",
    "\n",
    "# Call by_sex.apply with the function c_deck_survival\n",
    "c_surv_by_sex = by_sex.apply(c_deck_survival)\n",
    "\n",
    "# Print the survival rates\n",
    "print(c_surv_by_sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and filtering with .filter()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Read the CSV file into a DataFrame: sales\n",
    "sales = pd.read_csv('sales.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Group sales by 'Company': by_company\n",
    "by_company = sales.groupby('Company')\n",
    "\n",
    "# Compute the sum of the 'Units' of by_company: by_com_sum\n",
    "by_com_sum = by_company['Units'].sum()\n",
    "print(by_com_sum)\n",
    "\n",
    "# Filter 'Units' where the sum is > 35: by_com_filt\n",
    "by_com_filt = by_company.filter(lambda g:g['Units'].sum() > 35)\n",
    "print(by_com_filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and grouping with .map()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create the Boolean Series: under10\n",
    "under10 = (titanic['age'] < 10).map({True:'under 10', False:'over 10'})\n",
    "\n",
    "# Group by under10 and compute the survival rate\n",
    "survived_mean_1 = titanic.groupby(under10)['survived'].mean()\n",
    "print(survived_mean_1)\n",
    "\n",
    "# Group by under10 and pclass and compute the survival rate\n",
    "survived_mean_2 = titanic.groupby([under10, 'pclass'])['survived'].mean()\n",
    "print(survived_mean_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Bringing it all together: Case Study -- Olympic Medals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .value_counts() for ranking\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Select the 'NOC' column of medals: country_names\n",
    "country_names = medals['NOC']\n",
    "\n",
    "# Count the number of medals won by each country: medal_counts\n",
    "medal_counts = country_names.value_counts()\n",
    "\n",
    "# Print top 15 countries ranked by medals\n",
    "print(medal_counts.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .pivot_table() to count medals by type\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Construct a pivot table counted from the DataFrame medals, aggregating by 'count'. Use 'NOC' as the index, 'Athlete' for the values, and 'Medal' for the columns.\n",
    "counted = medals.pivot_table(index='NOC', values='Athlete', columns='Medal', aggfunc='count')\n",
    "\n",
    "# Modify the DataFrame counted by adding a column counted['totals']. The new column 'totals' should contain the result of taking the sum along the columns (i.e., use .sum(axis='columns')).\n",
    "\n",
    "counted['totals'] = counted.sum(axis='columns')\n",
    "\n",
    "# Overwrite the DataFrame counted by sorting it with the .sort_values() method. Specify the keyword argument ascending=False.\n",
    "\n",
    "counted = counted.sort_values('totals', ascending=False)\n",
    "\n",
    "# Print the top 15 rows of counted\n",
    "\n",
    "print(counted.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying .drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Select the columns 'Event_gender' and 'Gender'.\n",
    "\n",
    "ev_gen = medals[['Event_gender','Gender']]\n",
    "\n",
    "# Create a dataframe ev_gen_uniques containing the unique pairs contained in ev_gen.\n",
    "\n",
    "ev_gen_uniques = ev_gen.drop_duplicates()\n",
    "\n",
    "# Print ev_gen_uniques\n",
    "\n",
    "print(ev_gen_uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding possible errors with groupby()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Group medals by 'Event_gender' and 'Gender'.\n",
    "\n",
    "medals_by_gender = medals.groupby(['Event_gender','Gender'])\n",
    "\n",
    "# Create a DataFrame with a group count: medal_count_by_gender\n",
    "\n",
    "medal_count_by_gender = medals_by_gender.count()\n",
    "\n",
    "# Print medal_count_by_gender\n",
    "print(medal_count_by_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locating suspicious data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a Boolean Series with a condition that captures the only row that has medals.Event_gender == 'W' and medals.Gender == 'Men'. Be sure to use the & operator.\n",
    "\n",
    "sus = (medals.Event_gender == 'W') & (medals.Gender == 'Men')\n",
    "\n",
    "# Use the Boolean Series to create a DataFrame called suspect with the suspicious row.\n",
    "\n",
    "suspect = medals[sus] \n",
    "\n",
    "# Print suspect\n",
    "print(suspect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .nunique() to rank by distinct sports\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Group medals by 'NOC': country_grouped\n",
    "\n",
    "country_grouped = medals.groupby('NOC')\n",
    "\n",
    "# Compute the number of distinct sports in which each country won medals. To do this, select the 'Sport' column from country_grouped and apply .nunique().\n",
    "\n",
    "Nsports = country_grouped.Sport.nunique()\n",
    "\n",
    "# Sort Nsports in descending order with .sort_values() and ascending=False.\n",
    "\n",
    "Nsports = Nsports.sort_values(ascending=False)\n",
    "\n",
    "# Print the top 15 rows of Nsports\n",
    "\n",
    "print(Nsports.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting USA vs. USSR Cold War Olympic Sports\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a Boolean Series that is True when 'Edition' is between 1952 and 1988: during_cold_war\n",
    "during_cold_war = (medals.Edition>=1952) & (medals.Edition<=1988)\n",
    "\n",
    "# Extract rows for which 'NOC' is either 'USA' or 'URS': is_usa_urs\n",
    "is_usa_urs = medals.NOC.isin(['USA', 'URS'])\n",
    "\n",
    "# Filter the medals DataFrame using during_cold_war and is_usa_urs to create a new DataFrame called cold_war_medals.\n",
    "\n",
    "cold_war_medals = medals.loc[during_cold_war & is_usa_urs]\n",
    "\n",
    "# Group cold_war_medals by 'NOC'\n",
    "country_grouped = cold_war_medals.groupby('NOC')\n",
    "\n",
    "# Create a Series Nsports from country_grouped using indexing & chained methods:\n",
    "## Extract the column 'Sport'.\n",
    "## Use .nunique() to get the number of unique elements in each group;\n",
    "## Apply .sort_values(ascending=False) to rearrange the Series.\n",
    "\n",
    "Nsports = country_grouped['Sport'].nunique().sort_values(ascending=False)\n",
    "\n",
    "# Print Nsports\n",
    "print(Nsports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting USA vs. USSR Cold War Olympic Medals\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Construct medals_won_by_country using medals.pivot_table().\n",
    "## The index should be the years ('Edition') & the columns should be country ('NOC')\n",
    "## The values should be 'Athlete' (which captures every medal regardless of kind) & the aggregation method should be 'count' (which captures the total number of medals won).\n",
    "\n",
    "medals_won_by_country = medals.pivot_table(index='Edition', columns='NOC', values='Athlete', aggfunc='count')\n",
    "\n",
    "# Create cold_war_usa_urs_medals by slicing the pivot table medals_won_by_country. Your slice should contain the editions from years 1952:1988 and only the columns 'USA' & 'URS' from the pivot table.\n",
    "\n",
    "cold_war_usa_urs_medals = medals_won_by_country.loc[1952:1988, ['USA','URS']]\n",
    "\n",
    "# Create the Series most_medals by applying the .idxmax() method to cold_war_usa_urs_medals. Be sure to use axis='columns'.\n",
    "\n",
    "most_medals = cold_war_usa_urs_medals.idxmax(axis='columns')\n",
    "\n",
    "# Print most_medals.value_counts()\n",
    "print(most_medals.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing USA Medal Counts by Edition: Line Plot"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a DataFrame usa with data only for the USA.\n",
    "usa = medals.loc[medals.NOC == 'USA']\n",
    "# or usa = medals[medals.NOC == 'USA']\n",
    "\n",
    "# Group usa by ['Edition', 'Medal'] and aggregate over 'Athlete'\n",
    "usa_medals_by_year = usa.groupby(['Edition', 'Medal'])['Athlete'].count()\n",
    "\n",
    "# Use .unstack() with level='Medal' to reshape the DataFrame usa_medals_by_year.\n",
    "\n",
    "usa_medals_by_year = usa_medals_by_year.unstack(level='Medal')\n",
    "\n",
    "# Plot the DataFrame usa_medals_by_year\n",
    "usa_medals_by_year.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing USA Medal Counts by Edition: Area Plot\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create the DataFrame: usa\n",
    "usa = medals[medals.NOC == 'USA']\n",
    "\n",
    "# Group usa by 'Edition', 'Medal', and 'Athlete'\n",
    "usa_medals_by_year = usa.groupby(['Edition', 'Medal'])['Athlete'].count()\n",
    "\n",
    "# Reshape usa_medals_by_year by unstacking\n",
    "usa_medals_by_year = usa_medals_by_year.unstack(level='Medal')\n",
    "\n",
    "# Create an area plot of usa_medals_by_year\n",
    "usa_medals_by_year.plot.area()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing USA Medal Counts by Edition: Area Plot with Ordered Medals\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Redefine the 'Medal' column of the DataFrame medals as an ordered categorical. To do this, use pd.Categorical() with three keyword arguments:\n",
    "## values = medals.Medal.\n",
    "## categories=['Bronze', 'Silver', 'Gold'].\n",
    "## ordered=True\n",
    "\n",
    "medals.Medal = pd.Categorical(values=medals.Medal, categories=['Bronze', 'Silver', 'Gold'], ordered=True)\n",
    "\n",
    "# Create the DataFrame: usa\n",
    "usa = medals[medals.NOC == 'USA']\n",
    "\n",
    "# Group usa by 'Edition', 'Medal', and 'Athlete'\n",
    "usa_medals_by_year = usa.groupby(['Edition', 'Medal'])['Athlete'].count()\n",
    "\n",
    "# Reshape usa_medals_by_year by unstacking\n",
    "usa_medals_by_year = usa_medals_by_year.unstack(level='Medal')\n",
    "\n",
    "# Create an area plot of usa_medals_by_year\n",
    "usa_medals_by_year.plot.area()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
