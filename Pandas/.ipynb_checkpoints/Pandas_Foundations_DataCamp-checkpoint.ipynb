{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Ingestion and Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy and pandas working together "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Assign the numerical values in the DataFrame df to an array np_vals using the attribute values\n",
    "np_vals = df.values\n",
    "\n",
    "# Pass np_vals into the NumPy method log10() and store the results in np_vals_log10\n",
    "np_vals_log10 = np.log10(np_vals)\n",
    "\n",
    "# Pass the entire df DataFrame into the NumPy method log10() and store the results in df_log10\n",
    "df_log10 = np.log10(df)\n",
    "\n",
    "# Inspect the output of the print() code to see the type() of the variables that you created\n",
    "[print(x, 'has type', type(eval(x))) for x in ['np_vals', 'np_vals_log10', 'df', 'df_log10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building DataFrames from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frames from Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  weekday    city  visitors  signups\n",
      "0     Sun  Austin       139        7\n",
      "1     Sun  Dallas       237       12\n",
      "2     Mon  Austin       326        3\n",
      "3     Mon  Dallas       456        5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'weekday': ['Sun', 'Sun', 'Mon', 'Mon'],\n",
    "'city': ['Austin', 'Dallas', 'Austin', 'Dallas'],\n",
    "'visitors': [139, 237, 326, 456],\n",
    "'signups': [7, 12, 3, 5]}\n",
    "users = pd.DataFrame(data)\n",
    "print(users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('city', ['Austin', 'Dallas', 'Austin', 'Dallas']), ('signups', [7, 12, 3, 5]), ('visitors', [139, 237, 326, 456]), ('weekday', ['Sun', 'Sun', 'Mon', 'Mon'])]\n",
      "     city  signups  visitors weekday\n",
      "0  Austin        7       139     Sun\n",
      "1  Dallas       12       237     Sun\n",
      "2  Austin        3       326     Mon\n",
      "3  Dallas        5       456     Mon\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cities = ['Austin', 'Dallas', 'Austin', 'Dallas']\n",
    "signups = [7, 12, 3, 5]\n",
    "visitors = [139, 237, 326, 456]\n",
    "weekdays = ['Sun', 'Sun', 'Mon', 'Mon']\n",
    "list_labels = ['city', 'signups', 'visitors', 'weekday']\n",
    "list_cols = [cities, signups, visitors, weekdays]\n",
    "zipped = list(zip(list_labels, list_cols))\n",
    "\n",
    "print(zipped)\n",
    "\n",
    "data = dict(zipped)\n",
    "users = pd.DataFrame(data)\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### broadcasting with dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   height sex\n",
      "0    59.0   M\n",
      "1    65.2   M\n",
      "2    62.9   M\n",
      "3    65.4   M\n",
      "4    63.7   M\n",
      "5    65.7   M\n",
      "6    64.1   M\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "heights = [ 59.0, 65.2, 62.9, 65.4, 63.7, 65.7, 64.1 ]\n",
    "data = {'height': heights, 'sex': 'M'}\n",
    "results = pd.DataFrame(data)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Make a string with the value 'PA': state\n",
    "state = 'PA'\n",
    "\n",
    "# Construct a dictionary (data) with 2 key:value pairs: 'state':state and 'city':cities\n",
    "data = {'state':state, 'city':cities}\n",
    "\n",
    "# Construct a pandas DataFrame from the dictionary you created and assign it to df\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   height (in) sex\n",
      "A         59.0   M\n",
      "B         65.2   M\n",
      "C         62.9   M\n",
      "D         65.4   M\n",
      "E         63.7   M\n",
      "F         65.7   M\n",
      "G         64.1   M\n"
     ]
    }
   ],
   "source": [
    "results.columns = ['height (in)', 'sex']\n",
    "results.index = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Exporting data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Use pd.read_csv() with the string data_file to read the CSV file into a DataFrame and assign it to df1\n",
    "df1 = pd.read_csv(data_file)\n",
    "\n",
    "# Create a list of new column labels - 'year', 'population' - and assign it to the variable new_labels.\n",
    "new_labels = ['year','population']\n",
    "\n",
    "# Reread the same file, again using pd.read_csv(), but this time, add the keyword arguments header=0 and names=new_labels. Assign the resulting DataFrame to df2.\n",
    "df2 = pd.read_csv(data_file, header=0, names=new_labels)\n",
    "\n",
    "# Print both the DataFrames\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Use pd.read_csv() without using any keyword arguments to read file_messy into a pandas DataFrame df1\n",
    "df1 = pd.read_csv(file_messy)\n",
    "\n",
    "# Print the output of df1.head()\n",
    "print(df1.head())\n",
    "\n",
    "# Using the keyword arguments delimiter=' ', header=3 and comment='#', use pd.read_csv() again to read file_messy into a new DataFrame df2.\n",
    "df2 = pd.read_csv(file_messy, delimiter=' ', header=3, comment='#')\n",
    "\n",
    "# Print the output of df2.head()\n",
    "print(df2.head())\n",
    "\n",
    "# Use the DataFrame method .to_csv() to save the DataFrame df2 to the variable file_clean. Be sure to specify index=False.\n",
    "df2.to_csv(file_clean, index=False)\n",
    "\n",
    "# Use the DataFrame method .to_excel() to save the DataFrame df2 to the file 'file_clean.xlsx'. Again, remember to specify index=False.\n",
    "df2.to_excel('file_clean.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting using pandas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create the plot with the DataFrame method df.plot(). Specify a color of 'red'.\n",
    "# Note: c and color are interchangeable as parameters here, but we ask you to be explicit and specify color.\n",
    "\n",
    "df.plot(color='red')\n",
    "\n",
    "# Use plt.xlabel() to give the plot an x-axis label of 'Hours since midnight August 1, 2010'.\n",
    "\n",
    "plt.title('Temparature in Austin')\n",
    "\n",
    "# Specify the x-axis label\n",
    "\n",
    "plt.xlabel('Hours since midnight August 1, 2010')\n",
    "\n",
    "# Use plt.ylabel() to give the plot a y-axis label of 'Temperature (degrees F)'\n",
    "\n",
    "plt.ylabel('Temperature (degrees F)')\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Plot all columns (default)\n",
    "df.plot()\n",
    "plt.show()\n",
    "\n",
    "# Plot all columns as subplots. To do so, you need to specify subplots=True inside .plot().\n",
    "\n",
    "df.plot(subplots=True)\n",
    "plt.show()\n",
    "\n",
    "# Plot a single column of dew point data. To do this, define a column list containing a single column name 'Dew Point (deg F)', and call df[column_list1].plot().\n",
    "\n",
    "column_list1 = ['Dew Point (deg F)']\n",
    "df['column_list1'].plot\n",
    "plt.show()\n",
    "\n",
    "# Plot two columns of data, 'Temperature (deg F)' and 'Dew Point (deg F)'. To do this, define a list containing those column names and pass it into df[], as df[column_list2].plot()\n",
    "\n",
    "column_list2 = ['Temperature (deg F)','Dew Point (deg F)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explotary Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas line plots"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a list of y-axis column names called y_columns consisting of 'AAPL' and 'IBM'.\n",
    "y_columns = ['AAPL', 'IBM']\n",
    "\n",
    "# Generate a line plot with x='Month' and y=y_columns as inputs.\n",
    "df.plot(x='Month', y=y_columns)\n",
    "\n",
    "# Give the plot a title of 'Monthly stock prices'.\n",
    "plt.title('Monthly stock prices')\n",
    "\n",
    "# Add the y-axis label\n",
    "plt.ylabel('Price ($US)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas scatter plots"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Generate a scatter plot with 'hp' on the x-axis and 'mpg' on the y-axis. Specify s=sizes\n",
    "df.plot(kind='scatter', x='hp', y='mpg', s=sizes)\n",
    "\n",
    "# Add the title\n",
    "plt.title('Fuel efficiency vs Horse-power')\n",
    "\n",
    "# Add the x-axis label\n",
    "plt.xlabel('Horse-power')\n",
    "\n",
    "# Add the y-axis label\n",
    "plt.ylabel('Fuel efficiency (mpg)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas box plots"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Make a list called cols of the column names to be plotted: 'weight' and 'mpg'.\n",
    "cols = ['weight','mpg']\n",
    "\n",
    "# Call plot on df[cols] to generate a box plot of the two columns in a single figure. To do this, specify subplots=True.\n",
    "df[cols].plot(kind = 'box', subplots = True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas hist, pdf, and cdf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This formats the plots such that they appear on separate rows\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "# Plot a PDF for the values in fraction with 30 bins between 0 and 30%. The range has been taken care of for you. ax=axes[0] means that this plot will appear in the first row.\n",
    "\n",
    "df.fraction.plot(ax=axes[0], kind='hist', bins=30, normed=True, range=(0,.3))\n",
    "plt.show()\n",
    "\n",
    "# Plot a CDF for the values in fraction with 30 bins between 0 and 30%. Again, the range has been specified for you. To make the CDF appear on the second row, you need to specify ax=axes[1].\n",
    "\n",
    "df.fraction.plot(ax=axes[1], kind='hist', bins=30, normed=True, cumulative=True, range=(0,.3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print the minimum value of the Engineering column\n",
    "print(df['Engineering'].min())\n",
    "\n",
    "# Print the maximum value of the Engineering column\n",
    "print(df['Engineering'].max())\n",
    "\n",
    "# Construct the mean percentage per year with .mean(axis='columns'). Assign the result to mean.\n",
    "mean = df.mean(axis='columns')\n",
    "\n",
    "# Plot the average percentage per year. Since 'Year' is the index of df, it will appear on the x-axis of the plot. No keyword arguments are needed in your call to .plot().\n",
    "\n",
    "mean.plot()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median vs. mean"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print summary statistics of the 'fare' column of df with .describe() and print(). Note: df.fare and df['fare'] are equivalent.\n",
    "\n",
    "print(df.fare.describe())\n",
    "\n",
    "# Generate a box plot of the fare column\n",
    "df.fare.plot(kind='box')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantiles"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print the number of countries reported in 2015. To do this, use the .count() method on the '2015' column of df.\n",
    "print(df['2015'].count())\n",
    "\n",
    "# Print the 5th and 95th percentiles of df. To do this, use the .quantile() method with the list [0.05, 0.95].\n",
    "print(df.quantile([0.05, 0.95]))\n",
    "\n",
    "# Generate a box plot\n",
    "years = ['1800','1850','1900','1950','2000']\n",
    "df[years].plot(kind='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standart Deviation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Compute and print the means of the January and March data using the .mean() method.\n",
    "print(january.mean(), march.mean())\n",
    "\n",
    "# Compute and print the standard deviations of the January and March data using the .std() method\n",
    "print(january.std(), march.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating populations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Compute the global mean and global standard deviations of df using the .mean() and .std() methods. Assign the results to global_mean and global_std.\n",
    "\n",
    "global_mean = df.mean()\n",
    "global_std = df.std()\n",
    "\n",
    "# Filter the 'US' population from the 'origin' column and assign the result to us\n",
    "us = df.loc[df['origin'] == 'US']\n",
    "\n",
    "# Compute the US mean and US standard deviation: us_mean, us_std\n",
    "us_mean = us.mean()\n",
    "us_std = us.std()\n",
    "\n",
    "# Print the differences\n",
    "print(us_mean - global_mean)\n",
    "print(us_std - global_std)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Inside plt.subplots(), specify the nrows and ncols parameters so that there are 3 rows and 1 column\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1)\n",
    "\n",
    "# Filter the rows where the 'pclass' column has the values 1 and generate a box plot of the 'fare' column.\n",
    "titanic.loc[titanic['pclass'] == 1].plot(ax=axes[0], y ='fare', kind ='box')\n",
    "\n",
    "# Filter the rows where the 'pclass' column has the values 2 and generate a box plot of the 'fare' column.\n",
    "titanic.loc[titanic['pclass'] == 2].plot(ax=axes[1], y='fare', kind='box')\n",
    "\n",
    "# Filter the rows where the 'pclass' column has the values 3 and generate a box plot of the 'fare' column.\n",
    "titanic.loc[titanic['pclass'] == 3].plot(ax=axes[2], y='fare', kind='box')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Indexing time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and using a DatetimeIndex\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Prepare a format string, time_format, using '%Y-%m-%d %H:%M' as the desired format.\n",
    "time_format = '%Y-%m-%d %H:%M'\n",
    "\n",
    "# Convert date_list into a datetime object by using the pd.to_datetime() function. Specify the format string you defined above and assign the result to my_datetimes.\n",
    "\n",
    "my_datetimes = pd.to_datetime(date_list, format=time_format)  \n",
    "\n",
    "# Construct a pandas Series called time_series using pd.Series() with temperature_list and my_datetimes. Set the index of the Series to be my_datetimes.\n",
    "time_series = pd.Series(temperature_list, index=my_datetimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial string indexing and slicing\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Extract data from ts0 for a single hour - the hour from 9pm to 10pm on 2010-10-11. Assign it to ts1\n",
    "ts1 = ts0.loc['2010-10-11 21:00:00':'2010-10-11 22:00:00']\n",
    "\n",
    "# Extract data from ts0 for a single day - July 4th, 2010 - and assign it to ts2\n",
    "ts2 = ts0.loc['July 4, 2010']\n",
    "\n",
    "# Extract data from ts0 for the second half of December 2010 - 12/15/2010 to 12/31/2010. Assign it to ts3.\n",
    "ts3 = ts0.loc['2010-12-15':'2010-12-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindexing the index"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a new time series ts3 by reindexing ts2 with the index of ts1. To do this, call .reindex() on ts2 and pass in the index of ts1 (ts1.index).\n",
    "\n",
    "ts3 = ts2.reindex(ts1.index)\n",
    "\n",
    "# Create another new time series, ts4, by calling the same .reindex() as above, but also specifying a fill method, using the keyword argument method=\"ffill\" to forward-fill values.\n",
    "\n",
    "ts4 = ts2.reindex(ts1.index, method='ffill')\n",
    "\n",
    "# Combine ts1 + ts2: sum12\n",
    "sum12 = ts1 + ts2\n",
    "\n",
    "# Combine ts1 + ts3: sum13\n",
    "sum13 = ts1 + ts3\n",
    "\n",
    "# Combine ts1 + ts4: sum14\n",
    "sum14 = ts1 + ts4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling and frequency\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Downsample the 'Temperature' column of df to 6 hour data using .resample('6h') and .mean(). Assign the result to df1.\n",
    "\n",
    "df1 = df['Temperature'].resample('6H').mean()\n",
    "\n",
    "# Downsample the 'Temperature' column of df to daily data using .resample('D') and then count the number of data points in each day with .count(). Assign the result df2.\n",
    "\n",
    "df2 = df['Temperature'].resample('D').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating and resampling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Use partial string indexing to extract temperature data for August 2010 into august.\n",
    "\n",
    "august = df['Temperature']['2010-August']\n",
    "\n",
    "# Use the temperature data for August and downsample to find the daily maximum temperatures. Store the result in august_highs.\n",
    "\n",
    "august_highs = august.resample('D').max()\n",
    "\n",
    "# Extract temperature data for February: february\n",
    "february = df['Temperature']['2010-February']\n",
    "\n",
    "# Downsample to obtain the daily lowest temperatures in February: february_lows\n",
    "february_lows = february.resample('D').min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling mean and frequency"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Extract data from 2010-Aug-01 to 2010-Aug-15: unsmoothed\n",
    "unsmoothed = df['Temperature']['2010-Aug-01':'2010-Aug-15']\n",
    "\n",
    "# Use .rolling() with a 24 hour window to smooth the mean temperature data. Assign the result to smoothed.\n",
    "smoothed = unsmoothed.rolling(window =24).mean()\n",
    "\n",
    "# Use a dictionary to create a new DataFrame august with the time series smoothed and unsmoothed as columns.\n",
    "august = pd.DataFrame({'smoothed':smoothed, 'unsmoothed':unsmoothed})\n",
    "\n",
    "# Plot both smoothed and unsmoothed data using august.plot().\n",
    "august.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample and roll with it\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Use partial string indexing to extract August 2010 temperature data, and assign to august.\n",
    "\n",
    "august = df['Temperature']['2010-Aug']\n",
    "\n",
    "# Resample to daily frequency, saving the maximum daily temperatures, and assign the result to daily_highs.\n",
    "daily_highs = august.resample('D').max()\n",
    "\n",
    "# As part of one long method chain, repeat the above resampling (or you can re-use daily_highs) and then combine it with .rolling() to apply a 7 day .mean() (with window=7 inside .rolling()) so as to smooth the daily highs. Assign the result to daily_highs_smoothed and print the result.\n",
    "\n",
    "daily_highs_smoothed = august.resample('D').max().rolling(window=7).mean()\n",
    "print(daily_highs_smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method chaining and filtering\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Use .str.strip() to strip extra whitespace from df.columns. Assign the result back to df.columns.\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# In the 'Destination Airport' column, extract all entries where Dallas ('DAL') is the destination airport. Use .str.contains('DAL') for this and store the result in dallas.\n",
    "\n",
    "dallas = df['Destination Airport'].str.contains('DAL')\n",
    "\n",
    "# Resample dallas such that you get the total number of departures each day. Store the result in daily_departures.\n",
    "\n",
    "daily_departures = dallas.resample('D').sum()\n",
    "\n",
    "# Generate summary statistics for daily Dallas departures using .describe(). Store the result in stats\n",
    "\n",
    "stats = daily_departures.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values and interpolation\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Replace the index of ts2 with that of ts1, and then fill in the missing values of ts2 by using .interpolate(how='linear'). Save the result as ts2_interp.\n",
    "\n",
    "ts2_interp = ts2.reindex(ts1.index).interpolate(how='linear')\n",
    "\n",
    "# Compute the difference between ts1 and ts2_interp. Take the absolute value of the difference with np.abs(), and assign the result to differences.\n",
    "\n",
    "differences = np.abs(ts1 - ts2_interp)\n",
    "\n",
    "# Generate and print summary statistics of the differences with .describe() and print().\n",
    "\n",
    "print(differences.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time zones and conversions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a Boolean mask, mask, such that if the 'Destination Airport' column of df equals 'LAX', the result is True, and otherwise, it is False.\n",
    "\n",
    "mask = df['Destination Airport'] == 'LAX'\n",
    "\n",
    "# Use the mask to filter for only the LAX rows. Assign the result to la.\n",
    "la = df[mask]\n",
    "\n",
    "# Concatenate the two columns la['Date (MM/DD/YYYY)'] and la['Wheels-off Time'] with a ' ' space in between. Pass this to pd.to_datetime() to create a datetime array of all the times the LAX-bound flights left the ground.\n",
    "\n",
    "times_tz_none = pd.to_datetime( la['Date (MM/DD/YYYY)'] + ' ' + la['Wheels-off Time'] )\n",
    "\n",
    "# Use Series.dt.tz_localize() to localize the time to 'US/Central'.\n",
    "times_tz_central = times_tz_none.dt.tz_localize('US/Central')\n",
    "\n",
    "# Use the .dt.tz_convert() method to convert datetimes from 'US/Central' to 'US/Pacific'.\n",
    "times_tz_pacific = times_tz_central.dt.tz_convert('US/Pacific')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting time series, datetime indexing\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Plot the raw data before setting the datetime index\n",
    "df.plot()\n",
    "plt.show()\n",
    "\n",
    "# Convert the 'Date' column into a collection of datetime objects: df.Date\n",
    "df.Date = pd.to_datetime(df.Date)\n",
    "\n",
    "# Set the index to be the converted 'Date' column\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Re-plot the DataFrame to see that the axis is now datetime aware!\n",
    "df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting date ranges, partial indexing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Plot the summer data\n",
    "df.Temperature['2010-Jun':'2010-Aug'].plot()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# Plot the one week data\n",
    "df.Temperature['2010-06-10':'2010-06-17'].plot()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in a data file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the data file: df\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# Print the output of df.head()\n",
    "print(df.head())\n",
    "\n",
    "# Read in the data file with header=None: df_headers\n",
    "df_headers = pd.read_csv(data_file, header=None)\n",
    "\n",
    "# Print the output of df_headers.head()\n",
    "print(df_headers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-assigning column names"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Convert the comma separated string column_labels to a list of strings using .split(','). Assign the result to column_labels_list.\n",
    "column_labels_list = column_labels.split(\",\")\n",
    "\n",
    "# Assign the new column labels to the DataFrame: df.columns\n",
    "df.columns = column_labels_list\n",
    "\n",
    "# Call df.drop() with list_to_drop and axis='columns'. Assign the result to df_dropped.\n",
    "df_dropped = df.drop(list_to_drop, axis='columns')\n",
    "\n",
    "# Print the output of df_dropped.head()\n",
    "print(df_dropped.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and tidying datetime data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Convert the date column to string: df_dropped['date']\n",
    "df_dropped['date'] = df_dropped['date'].astype(str)\n",
    "\n",
    "# Add leading zeros to the 'Time' column. This has been done for you.\n",
    "df_dropped['Time'] = df_dropped['Time'].apply(lambda x:'{:0>4}'.format(x))\n",
    "\n",
    "# Concatenate the new date and Time columns: date_string\n",
    "date_string = df_dropped['date'] + df_dropped['Time']\n",
    "\n",
    "# Convert the date_string Series to datetime: date_times\n",
    "date_times = pd.to_datetime(date_string, format='%Y%m%d%H%M')\n",
    "\n",
    "# Set the index to be the new date_times container: df_clean\n",
    "df_clean = df_dropped.set_index(date_times)\n",
    "\n",
    "# Print the output of df_clean.head()\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the numeric columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print the dry_bulb_faren temperature between 8 AM and 9 AM on June 20, 2011\n",
    "print(df_clean.loc['2011-6-20 8:00:00':'2011-6-20 9:00:00', 'dry_bulb_faren'])\n",
    "\n",
    "# Convert the 'dry_bulb_faren' column to numeric values with pd.to_numeric(). Specify errors='coerce'\n",
    "df_clean['dry_bulb_faren'] = pd.to_numeric(df_clean['dry_bulb_faren'], errors='coerce')\n",
    "\n",
    "# Print the transformed dry_bulb_faren temperature between 8 AM and 9 AM on June 20, 2011\n",
    "print(df_clean.loc['2011-6-20 8:00:00':'2011-6-20 9:00:00', 'dry_bulb_faren'])\n",
    "\n",
    "# Convert the 'wind_speed' and 'dew_point_faren' columns to numeric values with pd.to_numeric(). Again, specify errors='coerce'\n",
    "df_clean['wind_speed'] = pd.to_numeric(df_clean['wind_speed'], errors='coerce')\n",
    "df_clean['dew_point_faren'] = pd.to_numeric(df_clean['dew_point_faren'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal min, max, median"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print the median of the dry_bulb_faren column\n",
    "print(df_clean['dry_bulb_faren'].median())\n",
    "\n",
    "# Print the median of the dry_bulb_faren column for the time range '2011-Apr':'2011-Jun'\n",
    "print(df_clean.loc['2011-Apr':'2011-Jun', 'dry_bulb_faren'].median())\n",
    "\n",
    "# Print the median of the dry_bulb_faren column for the month of January\n",
    "print(df_clean.loc['2011-Jan', 'dry_bulb_faren'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal variance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Downsample df_clean by day and aggregate by mean: daily_mean_2011\n",
    "daily_mean_2011 = df_clean.resample('D').mean()\n",
    "\n",
    "# Extract the dry_bulb_faren column from daily_mean_2011 using .values: daily_temp_2011\n",
    "daily_temp_2011 = daily_mean_2011['dry_bulb_faren'].values\n",
    "\n",
    "# Downsample df_climate by day and aggregate by mean: daily_climate\n",
    "daily_climate = df_climate.resample('D').mean()\n",
    "\n",
    "# Extract the Temperature column from daily_climate using .reset_index(): daily_temp_climate\n",
    "daily_temp_climate = daily_climate.reset_index()['Temperature']\n",
    "\n",
    "# Reset the index of daily_climate and extract the Temperature column. To do this, first reset the index of daily_climate using the .reset_index() method, and then use bracket slicing to access 'Temperature'. Store the result as daily_temp_climate.\n",
    "\n",
    "difference = daily_temp_2011 - daily_temp_climate\n",
    "print(difference.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sunny or cloudy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Get the cases in df_clean where the sky is clear. That is, when 'sky_condition' equals 'CLR', assigning to is_sky_clear.\n",
    "is_sky_clear = df_clean['sky_condition']=='CLR'\n",
    "\n",
    "# Use .loc[] to filter df_clean by is_sky_clear, assigning to sunny.\n",
    "sunny = df_clean.loc[is_sky_clear]\n",
    "\n",
    "# Resample sunny by day then calculate the max\n",
    "sunny_daily_max = sunny.resample('D').max()\n",
    "\n",
    "# See the result\n",
    "sunny_daily_max.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Using df_clean, when does sky_condition contain 'OVC'?\n",
    "is_sky_overcast = df_clean['sky_condition'].str.contains('OVC')\n",
    "\n",
    "# Filter df_clean using is_sky_overcast\n",
    "overcast = df_clean.loc[is_sky_overcast]\n",
    "\n",
    "# Resample overcast by day then calculate the max\n",
    "overcast_daily_max = overcast.resample('D').max()\n",
    "\n",
    "# See the result\n",
    "overcast_daily_max.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# From previous steps\n",
    "is_sky_clear = df_clean['sky_condition']=='CLR'\n",
    "sunny = df_clean.loc[is_sky_clear]\n",
    "sunny_daily_max = sunny.resample('D').max()\n",
    "is_sky_overcast = df_clean['sky_condition'].str.contains('OVC')\n",
    "overcast = df_clean.loc[is_sky_overcast]\n",
    "overcast_daily_max = overcast.resample('D').max()\n",
    "\n",
    "# Calculate the mean of sunny_daily_max\n",
    "sunny_daily_max_mean = sunny_daily_max.mean()\n",
    "\n",
    "# Calculate the mean of overcast_daily_max\n",
    "overcast_daily_max_mean = overcast_daily_max.mean()\n",
    "\n",
    "# Print the difference (sunny minus overcast)\n",
    "print(sunny_daily_max_mean - overcast_daily_max_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekly average temperature and visibility"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the visibility and dry_bulb_faren columns and resample them: weekly_mean\n",
    "weekly_mean = df_clean[['visibility','dry_bulb_faren']].resample('W').mean()\n",
    "\n",
    "# Print the output of weekly_mean.corr()\n",
    "print(weekly_mean.corr())\n",
    "\n",
    "# Plot weekly_mean with subplots=True\n",
    "weekly_mean.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily hours of clear sky"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Get the cases in df_clean where the sky is clear. That is, when 'sky_condition' equals 'CLR', assigning the result to is_sky_clear.\n",
    "is_sky_clear = df_clean['sky_condition'] == 'CLR'\n",
    "\n",
    "# Resample is_sky_clear by day, assigning to resampled.\n",
    "resampled = is_sky_clear.resample('D')\n",
    "\n",
    "# See the result\n",
    "resampled"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# From previous step\n",
    "is_sky_clear = df_clean['sky_condition'] == 'CLR'\n",
    "resampled = is_sky_clear.resample('D')\n",
    "\n",
    "# Calculate the number of measured sunny hours per day as the sum of resampled, assigning to sunny_hours.\n",
    "\n",
    "sunny_hours = resampled.sum()\n",
    "\n",
    "# Calculate the total number of measured hours per day as the count of resampled, assigning to total_hours.\n",
    "\n",
    "total_hours = resampled.count()\n",
    "\n",
    "# Calculate the fraction of hours per day that were sunny\n",
    "\n",
    "sunny_fraction = sunny_hours / total_hours"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# From previous steps\n",
    "is_sky_clear = df_clean['sky_condition'] == 'CLR'\n",
    "resampled = is_sky_clear.resample('D')\n",
    "sunny_hours = resampled.sum()\n",
    "total_hours = resampled.count()\n",
    "sunny_fraction = sunny_hours / total_hours\n",
    "\n",
    "# Draw a box plot of sunny_fraction using .plot() with kind set to 'box'.\n",
    "sunny_fraction.plot(kind='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat or humidity"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Resample dew_point_faren and dry_bulb_faren by Month, aggregating the maximum values: monthly_max\n",
    "monthly_max = df_clean[['dew_point_faren','dry_bulb_faren']].resample('M').max()\n",
    "\n",
    "# Generate a histogram with bins=8, alpha=0.5, subplots=True\n",
    "monthly_max.plot(kind='hist', bins=8, alpha=0.5, subplots=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of high temperatures"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Extract the maximum temperature in August 2010 from df_climate: august_max\n",
    "august_max = df_climate.loc['2010-Aug','Temperature'].max()\n",
    "print(august_max)\n",
    "\n",
    "# Resample August 2011 temps in df_clean by day & aggregate the max value: august_2011\n",
    "august_2011 = df_clean.loc['2011-Aug','dry_bulb_faren'].resample('D').max()\n",
    "\n",
    "# Filter for days in august_2011 where the value exceeds august_max: august_2011_high\n",
    "august_2011_high = august_2011.loc[august_2011 > august_max]\n",
    "\n",
    "# Construct a CDF of august_2011_high using 25 bins. Remember to specify the kind, normed, and cumulative parameters in addition to bins.\n",
    "august_2011_high.plot(kind='hist', normed=True, cumulative=True, bins=25)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
